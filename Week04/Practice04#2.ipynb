{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html><h2>What is nlp??? </h2></html> \\nNatural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\\nThe study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\\n(In this post), you will discover what natural language processing is and why it is so important.\\nAfter reading this post, you will know => What natural language is and how it is different from other types of data.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_data = \"\"\"<html><h2>What is nlp??? </h2></html> \n",
    "Natural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\n",
    "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\n",
    "(In this post), you will discover what natural language processing is and why it is so important.\n",
    "After reading this post, you will know => What natural language is and how it is different from other types of data.\"\"\"\n",
    "\n",
    "str_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2-1\n",
    "def remove_html(text_data):\n",
    "    soup=BeautifulSoup(text_data,'lxml')\n",
    "    return soup.get_text()\n",
    "\n",
    "processed_text = remove_html(str_data)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "#2-2\n",
    "print('Punctuation: ', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    sent=[]\n",
    "    for t in text.split(' '):\n",
    "        no_punct=\"\".join([c for c in t if c not in string.punctuation])\n",
    "        sent.append(no_punct)\n",
    "        \n",
    "    sentence=\" \".join(s for s in sent)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is nlp  \n",
      "Natural Language Processing or NLP for short is broadly defined as the automatic manipulation of natural language like speech and text by software\n",
      "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers\n",
      "In this post you will discover what natural language processing is and why it is so important\n",
      "After reading this post you will know  What natural language is and how it is different from other types of data\n"
     ]
    }
   ],
   "source": [
    "rm_punct_sen=remove_punctuation(processed_text)\n",
    "print(rm_punct_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is nlp  \n",
      "natural language processing or nlp for short is broadly defined as the automatic manipulation of natural language like speech and text by software\n",
      "the study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers\n",
      "in this post you will discover what natural language processing is and why it is so important\n",
      "after reading this post you will know  what natural language is and how it is different from other types of data\n"
     ]
    }
   ],
   "source": [
    "lower_sen=rm_punct_sen.lower()\n",
    "print(lower_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(lower_sen.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'what'),\n",
       " ('is', 'be'),\n",
       " ('nlp', 'nlp'),\n",
       " (' \\n', ' \\n'),\n",
       " ('natural', 'natural'),\n",
       " ('language', 'language'),\n",
       " ('processing', 'processing'),\n",
       " ('or', 'or'),\n",
       " ('nlp', 'nlp'),\n",
       " ('for', 'for'),\n",
       " ('short', 'short'),\n",
       " ('is', 'be'),\n",
       " ('broadly', 'broadly'),\n",
       " ('defined', 'define'),\n",
       " ('as', 'as')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_lem_sen=[(token.text,token.lemma_) for token in doc]\n",
    "tok_lem_sen[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "print(stopwords.words('english')[:10])\n",
    "print(len(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'be', 'nlp', ' \\n', 'natural', 'language', 'processing', 'or', 'nlp', 'for', 'short', 'be', 'broadly', 'define', 'as', 'the', 'automatic', 'manipulation', 'of', 'natural', 'language', 'like', 'speech', 'and', 'text', 'by', 'software', '\\n', 'the', 'study', 'of', 'natural', 'language', 'processing', 'have', 'be', 'around', 'for', 'more', 'than', '50', 'year', 'and', 'grow', 'out', 'of', 'the', 'field', 'of', 'linguistic', 'with', 'the', 'rise', 'of', 'computer', '\\n', 'in', 'this', 'post', 'you', 'will', 'discover', 'what', 'natural', 'language', 'processing', 'be', 'and', 'why', 'it', 'be', 'so', 'important', '\\n', 'after', 'read', 'this', 'post', 'you', 'will', 'know', ' ', 'what', 'natural', 'language', 'be', 'and', 'how', 'it', 'be', 'different', 'from', 'other', 'type', 'of', 'datum']\n"
     ]
    }
   ],
   "source": [
    "token_lem_sen=[token.lemma_ for token in doc]\n",
    "print(token_lem_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'be', 'nlp', ' \\n', 'natural', 'language', 'processing', 'or', 'nlp', 'for', 'short', 'be', 'broadly', 'define', 'as', 'the', 'automatic', 'manipulation', 'of', 'natural', 'language', 'like', 'speech', 'and', 'text', 'by', 'software', '\\n', 'the', 'study', 'of', 'natural', 'language', 'processing', 'have', 'be', 'around', 'for', 'more', 'than', '50', 'year', 'and', 'grow', 'out', 'of', 'the', 'field', 'of', 'linguistic', 'with', 'the', 'rise', 'of', 'computer', '\\n', 'in', 'this', 'post', 'you', 'will', 'discover', 'what', 'natural', 'language', 'processing', 'be', 'and', 'why', 'it', 'be', 'so', 'important', '\\n', 'after', 'read', 'this', 'post', 'you', 'will', 'know', ' ', 'what', 'natural', 'language', 'be', 'and', 'how', 'it', 'be', 'different', 'from', 'other', 'type', 'of', 'datum'] \n",
      "\n",
      "['nlp', ' \\n', 'natural', 'language', 'processing', 'nlp', 'short', 'broadly', 'define', 'automatic', 'manipulation', 'natural', 'language', 'like', 'speech', 'text', 'software', '\\n', 'study', 'natural', 'language', 'processing', 'around', '50', 'year', 'grow', 'field', 'linguistic', 'rise', 'computer', '\\n', 'post', 'discover', 'natural', 'language', 'processing', 'important', '\\n', 'read', 'post', 'know', ' ', 'natural', 'language', 'different', 'type', 'datum']\n",
      "\n",
      "Removed word:  {'for', 'be', 'from', 'what', 'more', 'why', 'this', 'as', 'out', 'the', 'so', 'will', 'with', 'other', 'and', 'of', 'by', 'than', 'you', 'it', 'after', 'have', 'in', 'how', 'or'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "print(token_lem_sen,'\\n')\n",
    "\n",
    "rmv_sw_sen=[w for w in token_lem_sen if not w in stop_words]\n",
    "print(rmv_sw_sen)\n",
    "\n",
    "removed_word=[w for w in token_lem_sen if not w in rmv_sw_sen]\n",
    "print(\"\\nRemoved word: \",set(removed_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "import numpy as np\n",
    "dictionary={}\n",
    "\n",
    "def make_frequency_dict(text):\n",
    "    for word in text:\n",
    "        if word not in dictionary:\n",
    "            dictionary[word]=0\n",
    "        dictionary[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_frequency_dict(rmv_sw_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nlp': 2,\n",
       " ' \\n': 1,\n",
       " 'natural': 5,\n",
       " 'language': 5,\n",
       " 'processing': 3,\n",
       " 'short': 1,\n",
       " 'broadly': 1,\n",
       " 'define': 1,\n",
       " 'automatic': 1,\n",
       " 'manipulation': 1,\n",
       " 'like': 1,\n",
       " 'speech': 1,\n",
       " 'text': 1,\n",
       " 'software': 1,\n",
       " '\\n': 3,\n",
       " 'study': 1,\n",
       " 'around': 1,\n",
       " '50': 1,\n",
       " 'year': 1,\n",
       " 'grow': 1,\n",
       " 'field': 1,\n",
       " 'linguistic': 1,\n",
       " 'rise': 1,\n",
       " 'computer': 1,\n",
       " 'post': 2,\n",
       " 'discover': 1,\n",
       " 'important': 1,\n",
       " 'read': 1,\n",
       " 'know': 1,\n",
       " ' ': 1,\n",
       " 'different': 1,\n",
       " 'type': 1,\n",
       " 'datum': 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural', 5),\n",
       " ('language', 5),\n",
       " ('processing', 3),\n",
       " ('\\n', 3),\n",
       " ('nlp', 2),\n",
       " ('post', 2),\n",
       " (' \\n', 1),\n",
       " ('short', 1),\n",
       " ('broadly', 1),\n",
       " ('define', 1),\n",
       " ('automatic', 1),\n",
       " ('manipulation', 1),\n",
       " ('like', 1),\n",
       " ('speech', 1),\n",
       " ('text', 1),\n",
       " ('software', 1),\n",
       " ('study', 1),\n",
       " ('around', 1),\n",
       " ('50', 1),\n",
       " ('year', 1),\n",
       " ('grow', 1),\n",
       " ('field', 1),\n",
       " ('linguistic', 1),\n",
       " ('rise', 1),\n",
       " ('computer', 1),\n",
       " ('discover', 1),\n",
       " ('important', 1),\n",
       " ('read', 1),\n",
       " ('know', 1),\n",
       " (' ', 1),\n",
       " ('different', 1),\n",
       " ('type', 1),\n",
       " ('datum', 1)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_sorted=sorted(dictionary.items(),key=lambda x:x[1],reverse=True)\n",
    "vocab_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'natural': 1, 'language': 2, 'processing': 3, '\\n': 4, 'nlp': 5, 'post': 6}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={}\n",
    "i=0\n",
    "\n",
    "for(word,frequency) in vocab_sorted:\n",
    "    if frequency>1:\n",
    "        i+=1\n",
    "        word_to_index[word]=i\n",
    "\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'natural': 1, 'language': 2, 'processing': 3, '\\n': 4, 'nlp': 5, 'post': 6, 'OOV': 7}\n"
     ]
    }
   ],
   "source": [
    "word_to_index['OOV']=len(word_to_index)+1\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nlp', ' \\n', 'natural', 'language', 'processing', 'nlp', 'short', 'broadly', 'define', 'automatic', 'manipulation', 'natural', 'language', 'like', 'speech', 'text', 'software', '\\n', 'study', 'natural', 'language', 'processing', 'around', '50', 'year', 'grow', 'field', 'linguistic', 'rise', 'computer', '\\n', 'post', 'discover', 'natural', 'language', 'processing', 'important', '\\n', 'read', 'post', 'know', ' ', 'natural', 'language', 'different', 'type', 'datum']\n",
      "[5, 7, 1, 2, 3, 5, 7, 7, 7, 7, 7, 1, 2, 7, 7, 7, 7, 4, 7, 1, 2, 3, 7, 7, 7, 7, 7, 7, 7, 7, 4, 6, 7, 1, 2, 3, 7, 4, 7, 6, 7, 7, 1, 2, 7, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "encoded=[]\n",
    "print(rmv_sw_sen)\n",
    "\n",
    "for w in rmv_sw_sen:\n",
    "    encoded.append(word_to_index.get(w,word_to_index['OOV']))\n",
    "    \n",
    "print(encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
